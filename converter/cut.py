import torch
from pathlib import Path

def convert(sec):
    sec = sec % (24 * 3600)
    hour = sec // 3600
    sec %= 3600
    min = sec // 60
    sec %= 60
    return "%02d:%02d:%02d" % (hour, min, sec)

def cutAudio():
    from faster_whisper import WhisperModel
    from tqdm import tqdm
    from pydub import AudioSegment
    import fnmatch
    import glob, os

    print("–ù–∞—á–∏–Ω–∞—é —Ä–∞–±–æ—Ç—É —Å –∞—É–¥–∏–æ:")

    os.chdir("./")
    for file in glob.glob("*.mp3"):
        print(file)

        def time_to_sec(t1):
            h, m, s = map(int, t1.split(':'))
            return h * 3600 + m * 60 + s
            print("\n–í–≤–µ–¥–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh:mm:ss")
            t1 = input()
            t11: int = time_to_sec(t1)

        def time_to_sec(t2):
            h, m, s = map(int, t2.split(':'))
            return h * 3600 + m * 60 + s
            print("\n–í–≤–µ–¥–∏—Ç–µ –∫–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ hh:mm:ss")
            t2 = input()
            t22: int = time_to_sec(t2)

        from pydub import AudioSegment
        t_start = t11 * 1000  # –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Ç –Ω–∞—á–∞–ª–∞ - 0 * 1000
        t_end = t22 * 1000  # 60 —Å–µ–∫—É–Ω–¥ - –¥–æ 1-–π –º–∏–Ω—É—Ç—ã
        new_audio = AudioSegment.from_mp3(file)
        a = new_audio[t_start:t_end]
        a.export("fragment.mp3", format="mp3")

        print("üìå –ì–æ—Ç–æ–≤–æ! –ê—É–¥–∏–æ –≤—ã—Ä–µ–∑–∞–Ω–æ, –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è fragment.mp3.")
    else:
        print("\n–†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == '__main__':
    cutAudio()