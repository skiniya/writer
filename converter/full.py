# from google.colab import files
from faster_whisper import WhisperModel
from tqdm import tqdm
from pydub import AudioSegment
import glob, os

print("–ù–∞—á–∏–Ω–∞—é —Ä–∞–±–æ—Ç—É —Å –∞—É–¥–∏–æ:")
os.chdir("/content/")
for file in glob.glob("*.mp3"):
    print(file)
dst = "audio.wav"
sound = AudioSegment.from_mp3(file)
sound.set_channels(1)
sound = sound.set_frame_rate(16000)
sound = sound.set_channels(1)
sound.export(dst, format="wav")

# —Ñ–∞–π–ª –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –≤ wav
def convert(sec):
    sec = sec % (24 * 3600)
    hour = sec // 3600
    sec %= 3600
    min = sec // 60
    sec %= 60
    return "%02d:%02d:%02d" % (hour, min, sec)


model = WhisperModel("large-v2", device="cuda", compute_type="int8_float16")

segments, info = model.transcribe("audio.wav", beam_size=1)
print("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: %s (%d—Å) " % (convert(info.duration), info.duration))
print('–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç...')

myfile = open("text.txt", "a")
for segment in tqdm(segments, unit_scale=100, unit=' —Ü–∏–∫–ª–æ–≤', ascii=False, ncols=80, position=0,
                    total=(int(info.duration / 4)), dynamic_ncols=80, colour='#9ACD32'):
    myfile.write(segment.text)
myfile.close()

with open("text.txt", 'r+') as myfile:
    txt = myfile.read().replace('—ë', '–µ')
    myfile.seek(0)
    myfile.truncate()
    myfile.write(txt)
myfile.close()
print("\nüìå –ì–æ—Ç–æ–≤–æ! –ú–æ–∂–Ω–æ –∑–∞–±–∏—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ txt —Ñ–∞–π–ª–∞.")